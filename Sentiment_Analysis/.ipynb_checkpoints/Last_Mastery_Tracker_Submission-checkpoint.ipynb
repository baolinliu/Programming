{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Define Kneser-Ney smoothing in Plain English\n",
    "\n",
    "Kneser smoothing is a method to helps solve the problem of predicting ngrams with words that the training set has not seen before.  We create a probability of an unknown ngrams and word history and usage to predict how the next set of ngrams will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Define Parse Tree in Plain English\n",
    "\n",
    "A Parse Tree is a representation of the syntactic structure of sentence for context free grammar.  It allows us to work with individual parts of the sentence using subtrees.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec in Plain English\n",
    "\n",
    "Word2Vec is a neural network that turns words in a numerical representation.  Words are represented by continouous vectors with a continuous bag of words model.  This very important because you want to turn words into numbers becauase and represent it in a vector space becaues it is easier for computers to understand and to calculate.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Recall, Precision, F1 score by code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "#confusion matrix\n",
    "matrix = [[713 ,  8],\n",
    "         [ 33 , 80]]\n",
    "\n",
    "#True positive / (False Negative + True Positive)\n",
    "\n",
    "def confusion(matrix):\n",
    "    precision = matrix[1][1] / (matrix[1][1] + matrix[0][1]) \n",
    "    recall = matrix[1][1] / (matrix[1][1] + matrix[1][0])\n",
    "    f1_score = (2*precision*recall) / (recall + precision)\n",
    "    return \"precision: %s recall: %s fl_score: %s\" % (precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.909090909091 recall: 0.70796460177 fl_score: 0.796019900498\n"
     ]
    }
   ],
   "source": [
    "print confusion(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Recall and F1 score with existing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "1.0\n",
      "0.666666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score ,recall_score, confusion_matrix, f1_score\n",
    "y_true = np.array([1,0,1,0,1,0])\n",
    "y_pred = np.array([1,1,1,1,1,1])\n",
    "\n",
    "print precision_score(y_true, y_pred)\n",
    "print recall_score(y_true, y_pred)\n",
    "print f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Edit Distance Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def levenshtein(s1, s2):\n",
    "    \"\"\"Takes 2 words, returns Levenshtein distance.\n",
    "    \n",
    "    >>>levenshtein('foo', 'poo')\n",
    "    1\n",
    "    \n",
    "    >>>levenshtein('intention', 'execution')\n",
    "    5\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(s1) > len(s2): # If one word is shorter than the other then change the order (bookkeeping to be consistent)\n",
    "        s1 , s2 = s2 , s1\n",
    " \n",
    "    if len(s2) == 0: # Make are getting a real word, \n",
    "        # if we are not getting a real word the cost is simply dropping all the letters in one of the words i.e. the length\n",
    "        return len(s1)\n",
    " \n",
    "    previous_row = range(len(s2) + 1) # Creating an array of length of the second word+1\n",
    "   \n",
    "    for i, c1 in enumerate(s1): # Interate through the first word \n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2): # Interate through the second word\n",
    "            if c1 == c2:\n",
    "                current_row.append(previous_row[j])\n",
    "            else:\n",
    "                insertions = previous_row[j + 1] + 1 \n",
    "                deletions = current_row[-1] + 1\n",
    "                substitutions = previous_row[j] + 1\n",
    "                current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print levenshtein('foo', 'poo')\n",
    "print levenshtein('intention', 'execution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#using NLP Library\n",
    "\n",
    "from nltk.metrics import distance\n",
    "\n",
    "print distance.edit_distance('foo','poo')\n",
    "print distance.edit_distance('intention', 'execution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'Star'),\n",
       " ('The', 'Wars'),\n",
       " ('The', 'saga'),\n",
       " ('Star', 'Wars'),\n",
       " ('Star', 'saga'),\n",
       " ('Star', 'continues'),\n",
       " ('Wars', 'saga'),\n",
       " ('Wars', 'continues'),\n",
       " ('Wars', 'with'),\n",
       " ('saga', 'continues'),\n",
       " ('saga', 'with'),\n",
       " ('saga', 'this'),\n",
       " ('continues', 'with'),\n",
       " ('continues', 'this'),\n",
       " ('continues', 'seventh'),\n",
       " ('with', 'this'),\n",
       " ('with', 'seventh'),\n",
       " ('with', 'entry'),\n",
       " ('this', 'seventh'),\n",
       " ('this', 'entry'),\n",
       " ('seventh', 'entry')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import skipgrams\n",
    "sentence = \"The Star Wars saga continues with this seventh entry\"\n",
    "sentence = sentence.split(' ')\n",
    "sentence\n",
    "list(skipgrams(sentence, 2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'Star'), ('Star', 'Wars'), ('Wars', 'saga'), ('saga', 'continues'), ('continues', 'with'), ('with', 'this'), ('this', 'seventh'), ('seventh', 'entry')]\n",
      "[('The', 'Star', 'Wars'), ('Star', 'Wars', 'saga'), ('Wars', 'saga', 'continues'), ('saga', 'continues', 'with'), ('continues', 'with', 'this'), ('with', 'this', 'seventh'), ('this', 'seventh', 'entry')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "print list(ngrams(sentence,2))\n",
    "print list(ngrams(sentence,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence = \"The Star Wars saga continues with this seventh entry\"\n",
    "\n",
    "def bigram(sentence):\n",
    "    bigram  = []\n",
    "    sentence = sentence.split(' ')\n",
    "    for i in range(len(sentence)+1):\n",
    "        if len(sentence[i:i+2]) == 2:\n",
    "            bigram.append(sentence[i:i+2])\n",
    "    return bigram    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Star'],\n",
       " ['Star', 'Wars'],\n",
       " ['Wars', 'saga'],\n",
       " ['saga', 'continues'],\n",
       " ['continues', 'with'],\n",
       " ['with', 'this'],\n",
       " ['this', 'seventh'],\n",
       " ['seventh', 'entry']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trigram(sentence):\n",
    "    trigram  = []\n",
    "    sentence = sentence.split(' ')\n",
    "    for i in range(len(sentence)):\n",
    "        if len(sentence[i:i+3]) == 3:\n",
    "            trigram.append(sentence[i:i+3])\n",
    "    return trigram    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Star', 'Wars'],\n",
       " ['Star', 'Wars', 'saga'],\n",
       " ['Wars', 'saga', 'continues'],\n",
       " ['saga', 'continues', 'with'],\n",
       " ['continues', 'with', 'this'],\n",
       " ['with', 'this', 'seventh'],\n",
       " ['this', 'seventh', 'entry']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'Star', 'Wars'),\n",
       " ('Star', 'Wars', 'saga'),\n",
       " ('Wars', 'saga', 'continues'),\n",
       " ('saga', 'continues', 'with'),\n",
       " ('continues', 'with', 'this'),\n",
       " ('with', 'this', 'seventh'),\n",
       " ('this', 'seventh', 'entry')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sentence,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#disambiguate word sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('father.n.01')\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "\n",
    "sentence = \"Luke, I am your father.\"\n",
    "sentence = sentence.split(' ')\n",
    "print(lesk(sentence, 'father'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Synset('father.n.01'), u'a male parent (also used as a term of address to your father)')\n",
      "(Synset('forefather.n.01'), u'the founder of a family')\n",
      "(Synset('father.n.03'), u\"`Father' is a term of address for priests in some churches (especially the Roman Catholic Church or the Orthodox Catholic Church); `Padre' is frequently used in the military\")\n",
      "(Synset('church_father.n.01'), u'(Christianity) any of about 70 theologians in the period from the 2nd to the 7th century whose writing established and confirmed official church doctrine; in the Roman Catholic Church some were later declared saints and became Doctor of the Church; the best known Latin Church Fathers are Ambrose, Augustine, Gregory the Great, and Jerome; those who wrote in Greek include Athanasius, Basil, Gregory Nazianzen, and John Chrysostom')\n",
      "(Synset('father.n.05'), u'a person who holds an important or distinguished position in some organization')\n",
      "(Synset('father.n.06'), u'God when considered as the first person in the Trinity')\n",
      "(Synset('founder.n.02'), u'a person who founds or establishes some institution')\n",
      "(Synset('don.n.03'), u'the head of an organized crime family')\n",
      "(Synset('beget.v.01'), u'make children')\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "for ss in wn.synsets('father'):\n",
    "    print(ss, ss.definition())\n",
    "    \n",
    "# Based on the sysnet bank, father in this case is a male parent     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#code using an existing NLP library to tag part-of-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "pos_tag = nltk.pos_tag(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Luke,', 'NNP'),\n",
       " ('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('your', 'PRP$'),\n",
       " ('father.', 'NN')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "star_wars = TextBlob(\"Luke, I am your father.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Luke', u'NNP'),\n",
       " ('I', u'PRP'),\n",
       " ('am', u'VBP'),\n",
       " ('your', u'PRP$'),\n",
       " ('father', u'NN')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star_wars.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Luke', 'I']),\n",
       " WordList(['I', 'am']),\n",
       " WordList(['am', 'your']),\n",
       " WordList(['your', 'father'])]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star_wars.ngrams(n=2)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
